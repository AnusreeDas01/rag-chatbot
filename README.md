# ğŸ¤– RAG Chatbot â€“ Chat with Your Documents

A conversational AI chatbot powered by **LLMs + RAG (Retrieval-Augmented Generation)** that allows you to upload documents and ask natural questions â€” and it answers using only the content of the files you uploaded.

ğŸš€ **Live Demo**: [rag-chatbot.app](https://rag-chatbot-01.streamlit.app/)

---

## ğŸ“Œ Overview

The RAG Chatbot is a smart document-based Q&A assistant. Upload PDFs, DOCX, or TXT files â€” then ask questions in natural language and get answers with references to the document content.

---

## âœ¨ Features

- ğŸ“ Upload `.pdf`, `.docx`, or `.txt` files
- ğŸ” Retrieves relevant chunks using semantic search
- ğŸ§  Uses LLMs (OpenAI / Flan-T5) to answer based on file content
- ğŸ“ Source references included in responses
- ğŸ’¬ Chat-style UI with streamlit
- ğŸ’¾ Download chat history anytime
- ğŸ§¹ One-click clear chat + file reset
- ğŸ“± Fully responsive and mobile-ready

---

## ğŸ› ï¸ Tech Stack

| Layer        | Tools / Libraries |
|--------------|-------------------|
| **Frontend** | Streamlit, streamlit-lottie |
| **Backend**  | Python, LangChain, FAISS |
| **LLM**      | OpenAI GPT-3.5 / Flan-T5 |
| **Embeddings** | Sentence Transformers (`all-MiniLM-L6-v2`) |
| **Vector DB** | FAISS (in-memory) |
| **Deployment** | Streamlit Cloud |

---

## ğŸ“‚ Folder Structure

```bash

rag-chatbot/
â”œâ”€â”€ streamlit_app.py           # ğŸ’» Main Streamlit frontend app
â”œâ”€â”€ main/                      # ğŸ§  Core logic folder
â”‚   â”œâ”€â”€ utils.py               # ğŸ“„ File parsing, embedding generation
â”‚   â”œâ”€â”€ rag_engine.py          # ğŸ§© RAG logic: load index, query LLM
â”‚   â””â”€â”€ uploads/               # ğŸ“ Temporary uploaded file storage (can be empty)
â”œâ”€â”€ assets/                    # ğŸ¨ For animations, logos, etc.
â”‚   â””â”€â”€ virtual_assistant.json # ğŸ¤– Your Lottie animation file
â”œâ”€â”€ requirements.txt           # ğŸ“¦ Python dependencies
â””â”€â”€ README.md                  # ğŸ“˜ Project documentation


```

## âš™ï¸ How to Run Locally

```bash
1. Clone the project:
git clone https://github.com/AnusreeDas01/rag-chatbot.git
cd rag-chatbot

2. (Optional) Create virtual env:
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

3. Install required packages:
pip install -r requirements.txt

4. Run the app:
streamlit run streamlit_app.py

ğŸ” Environment Setup
For OpenAI (Optional):
In .streamlit/secrets.toml or in Streamlit Cloud settings:
OPENAI_API_KEY = "sk-xxxxxxxxxxxxxxxxxxxx"

ğŸŒ Streamlit Deployment
App is deployed here ğŸ‘‰ https://rag-chatbot-01.streamlit.app/
Hosted via Streamlit Cloud with public access. You can upload files, ask questions, download history, and reset everything cleanly.

ğŸ§  Use Cases
. Summarize HR or legal documents
. Chat with your academic PDFs
. Ask questions about internal process docs
. Personal knowledge base assistant

ğŸ“¸ Screenshots
Add custom screenshots here if needed (e.g., chat, upload, UI)

ğŸ‘©â€ğŸ’» Author
Made with ğŸ’œ by Anusree Das

ğŸ”— **GitHub**: [Anusree Das](https://github.com/AnusreeDas01)
ğŸ’¼ **LinkedIn**: [Anusree Das](https://www.linkedin.com/in/anusree-das-01)
ğŸŒ **Live Demo**: [rag-chatbot.app](https://rag-chatbot-01.streamlit.app/)

```
